{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/machrisaa/tensorflow-vgg\n",
    "#To use the VGG networks, the npy files for [VGG16 NPY](https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM) has to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/AdvML/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import vgg16 \n",
    "import utils\n",
    "import transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_layers(feature_tensor, num_classes):\n",
    "\n",
    "    feature_tensor_size = int(feature_tensor.shape[1])\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        feature_input = tf.placeholder_with_default(\n",
    "            feature_tensor,\n",
    "            [None, feature_tensor_size],\n",
    "            'feature_input')\n",
    "        \n",
    "        label_input = tf.placeholder(tf.int64, [None], name='label_input')\n",
    "    \n",
    "    logits = tf.layers.dense(feature_input, num_classes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=label_input, logits=logits)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    pred_prob = tf.nn.softmax(logits)\n",
    "    loss_summary = tf.summary.scalar('cross_entropy', loss)\n",
    "  \n",
    "    return feature_input, label_input, logits, train_step, pred_prob,loss_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(labels, logits):\n",
    "\n",
    "    prediction = tf.argmax(logits,1, name='pred_class')\n",
    "    #true_label = tf.argmax(labels, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, labels), tf.float32))\n",
    "    accuracy_summary=tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    return accuracy,accuracy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_train_step(session: tf.Session, current_step: int, summary_writer: tf.summary.FileWriter):\n",
    "    \n",
    "    _, ac,summary = session.run((train_step, accuracy,summary_op),\n",
    "                                  feed_dict={feature_input: training_data_set['features'],\n",
    "                                  label_input: training_data_set['labels']\n",
    "                                 })\n",
    "    \n",
    "    summary_writer.add_summary(summary, current_step)\n",
    "    \n",
    "    if current_step % 10 == 0:\n",
    "        print('Accuracy at step {0} is {1}'.format(current_step, ac))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_images(session: tf.Session):\n",
    "    \n",
    "    ac = session.run(accuracy,feed_dict={feature_input: validate_data_set['features'],\n",
    "                              label_input: validate_data_set['labels']\n",
    "                             })\n",
    "\n",
    "    return np.mean(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(session: tf.Session, test):\n",
    "\n",
    "    \n",
    "    pred = session.run(pred_prob,feed_dict={feature_input: test['features'],\n",
    "                              label_input: test['labels']})\n",
    "  \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(session,image_list,vgg, batch_size): \n",
    "    \n",
    "    \n",
    "    ite = int(len(image_list)/batch_size)\n",
    "    feature = np.array([],dtype=np.float32).reshape(0,1000)\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ite):\n",
    "        idx1_img = j * batch_size\n",
    "        idx2_img = idx1_img + batch_size \n",
    "   \n",
    "        imgbatches= []\n",
    "    \n",
    "        for i, (label, image) in enumerate(image_list[idx1_img:idx2_img]):\n",
    "            labels.append(label)\n",
    "            img = utils.load_image(image)\n",
    "            imgbatch=img.reshape((1, 224, 224, 3))\n",
    "            if(i==0):\n",
    "                imgbatches=imgbatch\n",
    "            else:\n",
    "                imgbatches= np.concatenate((imgbatches, imgbatch), 0)\n",
    "\n",
    "\n",
    "        feature_output = session.run(vgg.fc8, feed_dict={images: imgbatches})  \n",
    "        feature =  np.concatenate((feature,feature_output), axis = 0)\n",
    "        \n",
    "        #output['labels'] = np.stack(labels[idx1_img:idx2_img])\n",
    "        #output['features'] = np.stack(feature_output)\n",
    "        #matrix_path = os.path.join(\"./data\", str(image_list)+ str(idx1_img)+':'+str(idx2_img) + '.npy')\n",
    "        #np.save(matrix_path, output)\n",
    "        \n",
    "        print(j)\n",
    "    \n",
    "    return {\n",
    "        'labels': np.stack(labels),\n",
    "        'features': np.stack(feature)\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_LOG_DIR = './tmp/vgg16_log'\n",
    "if not os.path.exists(VGG_LOG_DIR):\n",
    "    os.makedirs(VGG_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chenyunwu/Desktop/proj5/vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 5s\n",
      "------------- Starting training ----------------\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Accuracy at step 0 is 0.42476850748062134\n",
      "Accuracy at step 10 is 0.9742699265480042\n",
      "Accuracy at step 20 is 0.9799679517745972\n",
      "Accuracy at step 30 is 0.98170405626297\n",
      "Accuracy at step 40 is 0.9837072491645813\n",
      "Accuracy at step 50 is 0.9850872755050659\n",
      "Accuracy at step 60 is 0.98615562915802\n",
      "Accuracy at step 70 is 0.9866898059844971\n",
      "Accuracy at step 80 is 0.9874910712242126\n",
      "Accuracy at step 90 is 0.9879807829856873\n",
      "Accuracy at step 100 is 0.9877136945724487\n",
      "Accuracy at step 110 is 0.9881142973899841\n",
      "0:00:27.327219\n",
      "------------- Training done! -------------------\n",
      "----------- Evaluating on testing --------------\n",
      "Evaluation accuracy was: 0.989182710647583\n",
      "0:00:00.089604\n",
      "----------- Doing testing --------------\n",
      "INFO:tensorflow:Looking for images in 'small'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start1 = datetime.now()\n",
    "with tf.Session() as session:\n",
    "    vgg = vgg16.Vgg16()\n",
    "    images = tf.placeholder(\"float\", [20, 224, 224, 3])  \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(images) \n",
    "\n",
    "    #feed_dict={feature_input: training_data_set['features'],\n",
    "                                  #label_input: training_data_set['labels']})\n",
    "    feature_t = tf.placeholder(\"float\", [20, 1000])   \n",
    "    feature_input, label_input, logits, train_step, pred_prob,loss_summary= make_final_layers(feature_t, 2)\n",
    "    accuracy, accuracy_summary= compute_accuracy(label_input, logits)\n",
    "    summary_op = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "    \n",
    "    \n",
    "    print('------------- Starting training ----------------')\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #training_data_set = get_feature(session, training_images, vgg)\n",
    "    #np.save('train_feature.npy',training_data_set)\n",
    "    training_data_set = np.load('train_feature.npy')\n",
    "    training_data_set = training_data_set.item()\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(os.path.join(VGG_LOG_DIR, 'retrained'), session.graph_def)\n",
    "    for i in range(120):\n",
    "        execute_train_step(session, i, summary_writer)\n",
    "        \n",
    "    end1 = datetime.now()\n",
    "    \n",
    "    training = end1-start1\n",
    "    print(training)\n",
    "    #summary_writer.close()  \n",
    "    \n",
    "    print('------------- Training done! -------------------')\n",
    "    #print('---------- Loading testing data ----------------')\n",
    "    #tlabels, timages = transfer_learning.get_testing_data(testing_images)\n",
    "    print('----------- Evaluating on testing --------------')\n",
    "    end2 = datetime.now()\n",
    "    \n",
    "    #validate_data_set = get_feature(session, testing_images, vgg)\n",
    "    #np.save('validate_feature.npy', validate_data_set)\n",
    "    validate_data_set  = np.load('validate_feature.npy')\n",
    "    validate_data_set  = validate_data_set.item()\n",
    "    \n",
    "    eval_accuracy = evaluate_images(session)\n",
    "    \n",
    "    print('Evaluation accuracy was: {0}'.format(eval_accuracy))\n",
    "    end3 = datetime.now()\n",
    "    test_time = end3-end2\n",
    "    print(test_time)\n",
    "    \n",
    "    print('----------- Doing testing --------------')\n",
    "    testing, _, _ = transfer_learning.create_image_lists('../data/test' , testing_percentage=0, max_number_images=13000)\n",
    "    #testing_feature = get_feature(session, testing, vgg)\n",
    "    #np.save('test_feature.npy', testing_feature)\n",
    "    \n",
    "    testing_feature  = np.load('test_feature.npy')\n",
    "    testing_feature   = testing_feature.item()  \n",
    "    test_result = get_prob(session, testing_feature)\n",
    "      \n",
    "    test_left = testing[12480:]\n",
    "    testing_feature_last = get_feature(session, test_left ,vgg, batch_size=20)\n",
    "    test_result_last = get_prob(session, testing_feature_last)\n",
    "    \n",
    "    test_result_full = np.concatenate((test_result,test_result_last), axis = 0)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "names = [re.search('[0-9]+',i[1]).group() for i in testing]\n",
    "vgg_result = np.column_stack((names,test_result_full))\n",
    "colnames = ['id','cat','dog']\n",
    "vgg_result_pd = pd.DataFrame(vgg_result, index=names, columns=colnames)\n",
    "vgg_result_pd.to_csv('vgg_full.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
